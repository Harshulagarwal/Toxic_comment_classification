{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "trusted": true,
    "_uuid": "f00059c879ed11b8e731f2366337c20b2d82f80b"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('../input/train.csv')\n",
    "test=pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "trusted": true,
    "_uuid": "9607cfd2f3145960489e507adca517de18418cd5"
   },
   "outputs": [],
   "source": [
    "x_train=train['comment_text']\n",
    "y_train=train.iloc[:,2:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "trusted": true,
    "_uuid": "6f1f0b191cd1cf2b52cae1c362dfe8b75bbcdcb2"
   },
   "outputs": [],
   "source": [
    "x_test=test['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "cd1b2b68fe9946581e8c36be2151b30b8a14a021"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "clean_data=[]\n",
    "for sent in x_train:     \n",
    "    sent=sent.lower()\n",
    "    sent = re.sub(\"[^\\w]\", \" \", sent)\n",
    "    sent = re.sub(r\"\\d+\", \" \", sent)\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    clean_data.append(sent)\n",
    "clean_data = '\\n'.join(clean_data)\n",
    "clean_data=clean_data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "4d658851549732380b83b8a178f6142a152ccdd3"
   },
   "outputs": [],
   "source": [
    "type(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "5904b2a20f45634704cf9077f635a0a71df8de29"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "x_data=[]\n",
    "for sentence in clean_data:\n",
    "    sentence=sentence.split(' ')\n",
    "    word =[word for word in sentence if word not in stopwords.words('english')]\n",
    "    x_data.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "a045cbbac84f24c7a18f5b6cdad1eb4fff29668a"
   },
   "outputs": [],
   "source": [
    "clean_datat=[]\n",
    "for sent in x_test:\n",
    "        sent=sent.lower()\n",
    "        sent = re.sub(\"[^\\w]\", \" \", sent)\n",
    "        sent = re.sub(r\"\\d+\", \" \", sent)\n",
    "        sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "\n",
    "        clean_datat.append(sent)\n",
    "clean_datat = '\\n'.join(clean_datat)\n",
    "clean_datat=clean_datat.split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "f67ed61ea587ffb762a9d01093db83428eaf593f"
   },
   "outputs": [],
   "source": [
    "test_data=[]\n",
    "for sentence in clean_datat:\n",
    "    sentence=sentence.split(' ')\n",
    "    word =[word for word in sentence if word not in stopwords.words('english')]\n",
    "    test_data.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "06ff8f0bac635d70c434ade2c320ba5ce4bdd660"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "token=Tokenizer(num_words=200,split=' ')\n",
    "token.fit_on_texts(x_data)\n",
    "x_train=token.texts_to_sequences(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "63a62c4a303a53e2dd88dbfc891017ba5f506f67"
   },
   "outputs": [],
   "source": [
    "token=Tokenizer(num_words=200,split=' ')\n",
    "token.fit_on_texts(test_data)\n",
    "x_tesr=token.texts_to_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "235d67ded82a590e87797342120380dfccf6bea9"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 100\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test=pad_sequences(x_tesr,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "9e7a77d5cdd6311d022236950ffded0d3b53b0e0"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "6722d60a214159f2d6546a75f50922edcc98604a"
   },
   "outputs": [],
   "source": [
    "from keras.layers import MaxPool1D\n",
    "\n",
    "embed_size = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(200, embed_size))\n",
    "model.add(Bidirectional(LSTM(32,return_sequences=True)))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation=\"softmax\"))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 2\n",
    "hist=model.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "89e792510904ffb5dfff47217fc8a02262e54992"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "eb571fcf9be98943b2577fa61538775317c04054"
   },
   "outputs": [],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "23d384695972c21d2285d28df957747c1259995d"
   },
   "outputs": [],
   "source": [
    "submission = ('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\n",
    "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = prediction\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "1570b9b972eb1e9974177e61f0507baa6377eb8e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['loss'],'g')\n",
    "plt.plot(hist.history['val_loss'],'r')\n",
    "\n",
    "plt.plot(hist.history['acc'],'b')\n",
    "plt.plot(hist.history['val_acc'],'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "54243a47fff654002da43832a071debda2f295bb"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "58080e864fd9e4282cb53973f8f3886d87ce1727"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
